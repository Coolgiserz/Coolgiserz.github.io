<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>自然语言处理 | CoolCats</title>
    <link>/category/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/</link>
      <atom:link href="/category/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <description>自然语言处理</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 16 Mar 2024 21:22:46 +0800</lastBuildDate>
    <image>
      <url>/media/icon_hue03491371183284312b8b116a73ae5ab_79511_512x512_fill_lanczos_center_3.png</url>
      <title>自然语言处理</title>
      <link>/category/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/</link>
    </image>
    
    <item>
      <title>Text2sql技术工具调研与框架设计</title>
      <link>/post/text2sql-investigation/</link>
      <pubDate>Sat, 16 Mar 2024 21:22:46 +0800</pubDate>
      <guid>/post/text2sql-investigation/</guid>
      <description>&lt;h2 id=&#34;工具&#34;&gt;工具&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/642719916&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DB-GPT-Hub：基于LLM的Text-to-SQL解析框架&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gitee.com/Samuelcoding/NL2SQL&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NL2SQL: Text2SQL 语义解析数据集、解决方案、paper资源整合项目&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/BeachWang/DAIL-SQL&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/BeachWang/DAIL-SQL&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ai2sql.io/text2sql&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Text2SQL: A Powerful Tool for Querying Databases with Natural Language&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;功能需求分类&#34;&gt;功能需求分类&lt;/h2&gt;
&lt;h3 id=&#34;基本需求&#34;&gt;基本需求&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;单数据库、单数据表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;单数据库、多数据表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多数据库、多数据表&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;安全需求&#34;&gt;安全需求&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;防止自然语言触发的SQL注入&lt;/p&gt;
&lt;p&gt;需要sql注入检测、过滤机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防止自然语言生成的DDOS数据库攻击/执行高耗时语句&lt;/p&gt;
&lt;p&gt;需要熔断机制&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;应用场景示例&#34;&gt;应用场景示例&lt;/h2&gt;
&lt;p&gt;用户输入意图：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;离西丽站最近的50个博物院，生成pgsql,xxxx(prompt)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;生成SQL：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WITH station_location AS &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    SELECT ST_GeomFromText&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;SRID=4326;POINT(114.2 22.37)&amp;#39;&lt;/span&gt;, 4326&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; AS location          -- Replace x_coord and y_coord with actual coordinates
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SELECT m.instname, m.geo, ST_Distance&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;m.geo, s.location&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; AS distance
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;FROM museum m, station_location s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;WHERE ST_DWithin&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;m.geo, s.location, 500&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ORDER BY distance ASC
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LIMIT 50&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行查询：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/text2sql-investigation/images/demo/query_museum_hu42f84c661dd7c8c6e1196620aa110334_296943_c6ba022baed06dda7048ea615c7ef28a.webp 400w,
               /post/text2sql-investigation/images/demo/query_museum_hu42f84c661dd7c8c6e1196620aa110334_296943_03c83870d946ee3cb848725c5b39cc0b.webp 760w,
               /post/text2sql-investigation/images/demo/query_museum_hu42f84c661dd7c8c6e1196620aa110334_296943_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;/post/text2sql-investigation/images/demo/query_museum_hu42f84c661dd7c8c6e1196620aa110334_296943_c6ba022baed06dda7048ea615c7ef28a.webp&#34;
               width=&#34;760&#34;
               height=&#34;383&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;语义解析：将自然语言输入解析成结构化数据，表示查询中涉及的概念及概念间关系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实体识别：表名、列名、值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;语义匹配：将自然语言中识别出的实体与数据库中的实体进行匹配&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;查询生成：生成对应的SQL语句&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;语义解析&#34;&gt;语义解析&lt;/h3&gt;
&lt;p&gt;语义解析时，除了从用户输入中对概念实体进行识别，可能还需要精确数据（如用户希望查询或查询条件需要精细的数据：xxx名称、坐标地点、身份证号码等）查询，精确数据不一定在大模型训练数据集中存在，所以可能需要接入私有数据库或借助第三方数据API进行精细数据获取，其中会涉及用户意图细节补全。&lt;/p&gt;
&lt;h2 id=&#34;实现思路&#34;&gt;实现思路&lt;/h2&gt;
&lt;p&gt;第一步：简单考虑，针对给定的表结构提示，针对单表进行text2sql查询&lt;/p&gt;
&lt;p&gt;第二步：给定数据库，针对数据库内表结构进行text2sql&lt;/p&gt;
&lt;p&gt;第三步：给定数据库连接（只读），模型自动学习数据库表结构，生成对应prompt，进行text2SQL&lt;/p&gt;
&lt;p&gt;第四步：指定多个数据源，模型需要判断查询哪些数据源，&amp;hellip;。&lt;/p&gt;
&lt;p&gt;拓展：并行调用&lt;/p&gt;
&lt;h2 id=&#34;代码骨架设计&#34;&gt;代码骨架设计&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;模型（大语言模型）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;流水线（对话循环）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提示模板&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任务（text2SQL, &amp;hellip;&amp;hellip;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;配置&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;测试用例&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通用工具（日志、数据库驱动、搜索引擎）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/text2sql-investigation/images/demo/arch_hu802ca09f74bb2120882962cb8188af10_376958_177d6358b033d933f3b22abe11281ac3.webp 400w,
               /post/text2sql-investigation/images/demo/arch_hu802ca09f74bb2120882962cb8188af10_376958_6a16a73a5d83941c478193be413b48b1.webp 760w,
               /post/text2sql-investigation/images/demo/arch_hu802ca09f74bb2120882962cb8188af10_376958_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;/post/text2sql-investigation/images/demo/arch_hu802ca09f74bb2120882962cb8188af10_376958_177d6358b033d933f3b22abe11281ac3.webp&#34;
               width=&#34;760&#34;
               height=&#34;379&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;辅助工具&#34;&gt;辅助工具&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;搜索引擎&lt;/p&gt;
&lt;p&gt;bing search api&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;示例&#34;&gt;示例&lt;/h2&gt;
&lt;h3 id=&#34;基本测试&#34;&gt;基本测试&lt;/h3&gt;
&lt;h4 id=&#34;glm4&#34;&gt;GLM4&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;大模型是否可以判断用户问题是否“可解”&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;question:  世界上生与死的距离是否大于1公里？ code:  1
answer: 由于这个问题并没有直接或间接地表明需要查询数据库，也没有提供具体的数据库表结构信息，因此我无法生成相应的Postgres查询语句。根据您给出的规则，我应该返回：
0
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;question:  屏幕前的你和屏幕前的我现在是否正在熬夜？ code:  1
由于这个问题并不包含任何直接的查询意图，我无法生成一条Postgres查询语句。因此，根据您的要求，我会返回0。

0
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;大模型是否可以判断现有库表结构对回答用户问题的可支持程度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从下面示例可以看出，虽然大模型会对作出假设给出相应的查询语句，但其也会根据给定数据库表结构来判断问题实际是否能被现有数据支持。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;question:  南京路和北京路距离有多远？ code:  1
根据用户提出的问题，似乎用户希望得知的是两个地点（可能是以“南京路”和“北京路”命名的道路）之间的距离。但是，由于没有提供具体的表结构信息，我们无法直接生成一条准确的PostgreSQL查询语句。

如果假设用户是在请求城市中具体命名的道路之间的距离，并且我们的数据库中有相关道路的地理信息，那么理论上我们可以使用postGIS的函数来计算这两点之间的距离。

以下是一个假设性的查询语句，它假定：

- 数据库中有一个名为`roads`的表，其中包含道路的名称和地理数据。
- `geom`列包含的是postGIS支持的地理数据类型，如`LINESTRING`。
- `name`列包含道路的名称。

查询语句如下：

```sql
SELECT ST_Distance(
    ST_Transform(
        ST_SetSRID(
            ST_MakePoint(
                ST_StartPoint(geom)::text, -- 假定geom是LINESTRING类型，获取起点
                ST_EndPoint(geom)::text    -- 获取终点
            ),
        4326), -- 设置为WGS84坐标系
    900913), -- 转换为米制坐标系，适合计算距离
    ST_Transform(
        ST_SetSRID(
            ST_MakePoint(
                (SELECT ST_StartPoint(geom)::text FROM roads WHERE name = &amp;#39;北京路&amp;#39;), -- 假定找到北京路的起点
                (SELECT ST_EndPoint(geom)::text FROM roads WHERE name = &amp;#39;北京路&amp;#39;)    -- 假定找到北京路的终点
            ),
        4326),
    900913)
) / 1000 AS distance_in_km
FROM roads
WHERE name = &amp;#39;南京路&amp;#39;; -- 假定找到南京路的起点和终点
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果数据库中不存在这样的表和列，或者用户的问题实际上与数据库查询无关，那么按照您的要求，应当返回1，因为现有的信息不足以支持用户的查询需求。&lt;/p&gt;
&lt;p&gt;由于用户的问题不是很明确，这里我假设用户确实是在查询数据库中的信息，因此提供了上述查询语句。如果实际情况下用户的问题并不涉及数据库查询，正确的回应应当是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plaintext&#34; data-lang=&#34;plaintext&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;表示现有数据库表结构不足以支持用户的查询需求。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;
- 大模型生成的SQL是否合理
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;question:  天安门和地安门是否在同一个城市 code:  1
answer: 基于提供的参考信息，我可以判断天安门和地安门位于同一个城市，即中国的北京市。&lt;/p&gt;
&lt;p&gt;以下是针对用户可能的查询需求而生成的一条PostgreSQL查询语句（假设数据库中有一个名为&lt;code&gt;historic_buildings&lt;/code&gt;的表，且该表包含表示建筑名称和所在城市的字段）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COUNT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;historic_buildings&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;天安门&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;地安门&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;AND&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;city&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;北京市&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果天安门和地安门的相关信息确实保存在数据库中，并且表结构如假设所述，上述查询将返回2，表示这两个建筑都位于北京市。&lt;/p&gt;
&lt;p&gt;但是，如果数据库中并没有相关表或者字段来支持查询这两个建筑的信息，那么根据您的要求，应返回1。而如果用户输入的信息中不存在查询意图，则应返回0。&lt;/p&gt;
&lt;p&gt;由于这里是假设性回答，并且没有具体的数据库结构信息，以上查询只是根据用户需求的可能情景而构造的示例。实际情况中，需要根据数据库的具体结构和内容来确定查询语句。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Multilabel Text Classification for Policy</title>
      <link>/project/multilabel-text-classification-for-policy/</link>
      <pubDate>Mon, 15 Jan 2024 00:57:06 +0800</pubDate>
      <guid>/project/multilabel-text-classification-for-policy/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;硬件：Nvidia RTX 4090 24G&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任务类型：多标签文本分类&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预训练模型：Ernie3 Base&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;训练方法：基于预训练模型进行微调，先基于AdamW优化器使模型快速达到较优的效果，再使用SGD优化器精调&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优化策略：针对数据类别不平衡情况，采样训练集时刻意尽量提高类别较少样本的比例。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;评价方法：多标签微平均&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;结果：通过测试，投入生产使用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>NLP任务——事件抽取</title>
      <link>/post/event-extraction-algorithms-summary/</link>
      <pubDate>Sun, 05 Nov 2023 20:26:20 +0800</pubDate>
      <guid>/post/event-extraction-algorithms-summary/</guid>
      <description>&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;p&gt;事件抽取关注如何从非结构化的文本中自动抽取结构化信息的问题，如用户之间的偏爱、项目投资关系等。&lt;/p&gt;
&lt;h3 id=&#34;什么是事件event&#34;&gt;什么是事件（event）&lt;/h3&gt;
&lt;p&gt;事件具有什么要素？如何定义一个事件？当我们描述一个事件时，需要描述那些要素才足够充分？&lt;/p&gt;
&lt;p&gt;触发词识别、事件类型分类、论元识别、角色分类&lt;/p&gt;
&lt;h3 id=&#34;相关数据&#34;&gt;相关数据&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://tianchi.aliyun.com/dataset/110901&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CCKS2021金融领域事件因果关系抽取数据集_数据集-阿里云天池&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://tianchi.aliyun.com/dataset/136800&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CCKS2022金融领域FEW-SHOT事件抽取数据集_数据集-阿里云天池&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://cail.cipsc.org.cn/task1.html?raceID=1&amp;amp;cail_tag=2022&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CAIL 2022 事件检测&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;相关工具包&#34;&gt;相关工具包&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://nlp.csai.tsinghua.edu.cn/news/omnievent&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://nlp.csai.tsinghua.edu.cn/news/omnievent&lt;/a&gt;事件抽取开源工具包/&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://nlp.csai.tsinghua.edu.cn/project/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://nlp.csai.tsinghua.edu.cn/project/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;相关博客&#34;&gt;相关博客&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>基于类别的Yelp评论情感分析系统</title>
      <link>/project/aspect-based-sentiment-analysis-on-yelp-dataset/</link>
      <pubDate>Mon, 11 Jan 2021 09:18:49 +0800</pubDate>
      <guid>/project/aspect-based-sentiment-analysis-on-yelp-dataset/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NLP入门必看</title>
      <link>/project/nlp-learning-for-newbee/</link>
      <pubDate>Thu, 24 Dec 2020 14:17:50 +0800</pubDate>
      <guid>/project/nlp-learning-for-newbee/</guid>
      <description>&lt;p&gt;项目将涵盖：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自然语言处理基本概念、任务、问题&lt;/li&gt;
&lt;li&gt;经典自然语言处理技术及原理&lt;/li&gt;
&lt;li&gt;相关数据集汇总&lt;/li&gt;
&lt;li&gt;案例代码&lt;/li&gt;
&lt;li&gt;可用的编程框架&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>「论文翻译」- 你需要的只是注意力</title>
      <link>/publication/attention-is-all-you-need/</link>
      <pubDate>Wed, 30 Sep 2020 19:09:30 +0800</pubDate>
      <guid>/publication/attention-is-all-you-need/</guid>
      <description>&lt;h3 id=&#34;引言&#34;&gt;引言&lt;/h3&gt;
&lt;p&gt;循环神经网络，特别是长短期记忆[12]和门控循环[7]神经网络，已经被牢固地确立为语言建模和机器翻译等序列建模和转换问题的最先进方法[29，2，5]。此后，大量的努力继续推动循环语言模型和编码器-解码器架构的边界[31，21，13]。&lt;/p&gt;
&lt;p&gt;循环模型通常沿着输入和输出序列的符号位置进行因子计算。这种固有的顺序性使得我们无法训练实例中的并行化，这在较长的序列长度上变得至关重要，因为内存约束限制了跨实例的批处理。最近的工作通过因子化技巧[18]和条件计算[26]实现了计算效率的显著提高，同时也提高了后者情况下的模型性能。然而，顺序计算的基本约束仍然存在。&lt;/p&gt;
&lt;p&gt;注意力机制已经成为各种任务中引人注目的序列建模和推导模型的一个组成部分，允许对依赖关系进行建模，而不考虑它们在输入或输出序列中的距离[2，16]。然而，除少数情况外[22]，这种注意机制是与循环网络一起使用的。&lt;/p&gt;
&lt;p&gt;在这项工作中，我们提出了Transformer，一个摒弃递归的模型架构，而完全依靠注意力机制来绘制输入和输出之间的全局依赖关系。Transformer允许更多的并行化，并且在8个P100 GPU上训练12小时后，就可以在翻译质量上达到一个新的水平。&lt;/p&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;
&lt;p&gt;减少顺序计算的目标也构成了扩展神经GPU[20]、ByteNet[15]和ConvS2S[8]的基础，它们都使用卷积神经网络作为基本构件，对所有输入和输出位置并行计算隐藏表示。在这些模型中，将两个任意输入或输出位置的信号关联起来所需的运算次数随着位置之间的距离而增长，对于ConvS2S来说是线性的，对于ByteNet来说是对数的。这使得学习遥远位置之间的依赖关系变得更加困难[11]。在Transformer中，这种情况被减少到了恒定的操作次数，尽管代价是由于注意力加权位置的平均化而降低了有效的分辨率，我们用多头注意力来抵消这种效果，如3.2节所述。&lt;/p&gt;
&lt;p&gt;自注意力，有时也被称为内注意，是一种将单一序列的不同位置联系起来以计算序列表征的注意机制。自注意力已被成功地用于各种任务中，包括阅读理解、抽象总结、文本内涵和学习与任务无关的句子表征[4，22，23，19]。&lt;/p&gt;
&lt;p&gt;端到端记忆网络是基于循环注意机制而不是序列排列的循环，已被证明在简单语言问题回答和语言建模任务中表现良好[28]。&lt;/p&gt;
&lt;p&gt;然而，据我们所知，Transformer是第一个完全依靠自注意力来计算其输入和输出的表示，而不使用序列对齐的RNNs或卷积的转导模型。在下面的章节中，我们将描述Transformer，激励自注意力，并讨论其与[14，15]和[8]等模型相比的优势。&lt;/p&gt;
&lt;h3 id=&#34;模型架构&#34;&gt;模型架构&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./images/fig1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./images/fig2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;
&lt;p&gt;在这项工作中，我们提出了Transformer，这是第一个完全基于注意力的序列转换模型，用多头自注意力取代了编码器-解码器架构中最常用的循环层。&lt;/p&gt;
&lt;p&gt;对于翻译任务，Transformer的训练速度可以显著快于基于循环层或卷积层的架构。在WMT 2014英译德和WMT 2014英译法两个翻译任务上，我们实现了新的技术状态。在前一个任务中，我们的最佳模型甚至超过了之前报道的所有合集。&lt;/p&gt;
&lt;p&gt;我们对基于注意力的模型的未来感到兴奋，并计划将其应用于其他任务。我们计划将Transformer扩展到涉及文本以外的输入和输出模式的问题，并研究局部的、受限的注意力机制，以有效地处理图像、音频和视频等大型输入和输出。让生成的顺序性降低是我们的另一个研究目标。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>语料库和知识库系统</title>
      <link>/post/corpus-and-knowledge-based-system/</link>
      <pubDate>Thu, 16 Jul 2020 11:42:29 +0800</pubDate>
      <guid>/post/corpus-and-knowledge-based-system/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;语料库在自然语言处理中扮演者什么角色？&lt;/li&gt;
&lt;li&gt;知识库包括什么知识？&lt;/li&gt;
&lt;li&gt;什么是知识？&lt;/li&gt;
&lt;li&gt;语料库的建立需要什么技术/&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>基于隐马尔可夫模型实现简易词性分析器</title>
      <link>/project/pos-tagger-implemented-on-hmm-model/</link>
      <pubDate>Sat, 21 Mar 2020 20:23:11 +0800</pubDate>
      <guid>/project/pos-tagger-implemented-on-hmm-model/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本项目基于隐马尔可夫模型实现一个简易的词性标注器。首先简单介绍下面几个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;词性标注器是做什么的？&lt;/li&gt;
&lt;li&gt;如何实现词性标注？&lt;/li&gt;
&lt;li&gt;HMM模型的思想&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;词性标注&#34;&gt;词性标注&lt;/h3&gt;
&lt;h4 id=&#34;什么是词性&#34;&gt;什么是词性？&lt;/h4&gt;
&lt;p&gt;词性是词汇的基本语法属性，也称为词类。词性标注（Part-Of-Speech tagging）就是在给定句子中判定每个词的语法属性，确定其词性并加以标注。语文课上或者英语课上老师让同学们分析句子成分，其中就会用到词性的信息，比如说主语只能是名词、代词等等，谓语只能是动词、助动词、系动词等等……了解词汇、句子的语法特征在某些场合下有助于我们理解句意（更多介绍请移步语法书），所以词性标注是一个值得研究的问题。&lt;/p&gt;
&lt;h4 id=&#34;如何实现词性标注&#34;&gt;如何实现词性标注？&lt;/h4&gt;
&lt;p&gt;那么如何实现词性标注？首先要知道词性标注面临着什么问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;词具有兼类现象&lt;/p&gt;
&lt;p&gt;同一个词可能有多种词性，尤其是对于汉语来说，词语在词性方面的歧义数量极大。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;词性划分具有主观性&lt;/p&gt;
&lt;p&gt;语言学界对于词性的划分没有统一被广泛认可的划分标准。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;实现词性标注的方法可以分为以下几类：基于统计、基于规则、规则与统计融合的方法。
基于统计的方法若按照是否有标注数据来分又可以分为有监督和无监督的方法.&lt;/p&gt;
&lt;h3 id=&#34;基于隐马尔可夫模型进行词性标注&#34;&gt;基于隐马尔可夫模型进行词性标注&lt;/h3&gt;
&lt;h4 id=&#34;隐马尔可夫模型简要介绍&#34;&gt;隐马尔可夫模型简要介绍&lt;/h4&gt;
&lt;p&gt;隐马尔可夫模型（HMM）建模的是不可观测隐状态变量、可观测的变量及其转化关系的概率分布。HMM属于概率图模型的一类，属于生成模型。根据训练数据是否包括观测序列对应的状态序列可以分为有监督学习和无监督学习的方法。&lt;/p&gt;
&lt;p&gt;HMM认为在我们所能够观测到的变量背后实际上有一个隐含的状态变量，是这个隐含的变量决定了我们所能够观测到的现象，比如说我们看到了一串数字“6 5 1 3 4 2 1 2 5”，这串数字可能是由一个或多个骰子共投掷了9次所得到。所以要是能够把这个隐含变量的概率分布建模出来，那得到的模型就更能反应真实系统的工作机制。&lt;/p&gt;
&lt;p&gt;隐马尔可夫模型有两个基本假设：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;齐次马尔可夫性假设&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;即认为隐马尔可夫链在t时刻的状态只依赖于t-1时刻的状态，这背后的意思是认为t-1时刻的状态已经包含了足够预测t时刻状态的历史状态信息。如只通过今天的天气预测明天的天气而不去理会昨天、前天甚至更早以前的天气。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;观测独立性假设&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;任意时刻的观测只依赖于该时刻马尔可夫链的状态。&lt;/p&gt;
&lt;p&gt;隐马尔可夫模型主要有三大问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;概率计算：
给定状态转移概率、发射概率和初始概率，计算出现某观测序列的概率值&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;学习问题：
已知观测序列和状态集合，估计HMM的参数：状态转移矩阵、发射矩阵和初始概率&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预测问题（解码问题）：
给定观测序列和HMM的参数，求出最有可能的隐状态序列。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;为什么能用hmm模型进行词性分析&#34;&gt;为什么能用HMM模型进行词性分析？&lt;/h4&gt;
&lt;p&gt;词性分析的过程中，我们所能够观测到的就是词汇的序列，要分析词性是不能直接观测到的，可以把句子各单词的词性与HMM中的隐状态对应起来，观测到的单词与显状态对应起来，然后就能够通过HMM的框架建模单词与词性的关系了。&lt;/p&gt;
&lt;h4 id=&#34;如何用hmm模型实现词性分析&#34;&gt;如何用HMM模型实现词性分析？&lt;/h4&gt;
&lt;h5 id=&#34;明确变量和参数&#34;&gt;明确变量和参数&lt;/h5&gt;
&lt;p&gt;要清楚HMM有什么样的变量和参数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隐状态：词性&lt;/li&gt;
&lt;li&gt;显状态：词汇&lt;/li&gt;
&lt;li&gt;初始概率：句首词性的概率分布&lt;/li&gt;
&lt;li&gt;状态转移矩阵A：从一个词性到下一个词性的概率分布&lt;/li&gt;
&lt;li&gt;发射概率矩阵B：给定词性下词汇的概率分布&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;明确如何学习参数&#34;&gt;明确如何学习参数&lt;/h5&gt;
&lt;p&gt;此处以有监督的方式训练，可以直接通过统计算出:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;转移概率: $A[i][j]=\frac{N_{ij}}{N_i}$,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;发射概率: $B[i][v]=\frac{N_{iv}}{N_i}$,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;初始概率: $Pi[i]=\frac{N_{oi}}{N_o}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;明确如何进行推断&#34;&gt;明确如何进行推断&lt;/h5&gt;
&lt;p&gt;给定句子，求出最可能的词性标注序列。使用维特比算法。&lt;/p&gt;
&lt;h4 id=&#34;基于hmm模型的词性分析器有何缺点&#34;&gt;基于HMM模型的词性分析器有何缺点？&lt;/h4&gt;
&lt;p&gt;HMM的假设很简洁，也能够在一些简单场景下工作得很好，但成也简洁，败也简洁。所做的两个假设对于真实情况下的复杂语言现象而言还是过分简单了：t位置的词性不止受t-1位置的词性的影响，可能还受更前面的，甚至后面的词性的影响；词汇的词性本身可能存在歧义；……&lt;/p&gt;
&lt;h2 id=&#34;项目结构&#34;&gt;项目结构&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./images/framework.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;测试结果&#34;&gt;测试结果&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./images/test.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;更多扩展&#34;&gt;更多扩展&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于未登录词和分词，该如何处理？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何实现无监督的词性标注？&lt;/p&gt;
&lt;p&gt;如利用EM算法的Baum-Welch算法&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;相关资料&#34;&gt;相关资料&lt;/h2&gt;
&lt;h3 id=&#34;教材&#34;&gt;教材&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;统计学习方法第10章：隐马尔可夫模型&lt;/li&gt;
&lt;li&gt;统计自然语言处理第7章：自动分词、命名实体识别和词性标注&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;开源库&#34;&gt;开源库&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hmmlearn.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hmmlearn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;博客&#34;&gt;博客：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/113136120&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Forward-可能是最易懂且全面的隐马尔可夫介绍（一）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
